<div align="center">
<a href="http://camma.u-strasbg.fr/">
<img src="../files/logo_cholect50.gif" width="100%">
</a>
</div>

------------------------------------------------------

<div align="right"><a href="../README.md" id="links">Home</a> &nbsp;&nbsp;&nbsp; | &nbsp;&nbsp;&nbsp; 
<a href="README-Format.md" id="links">Data format</a> &nbsp;&nbsp;&nbsp; | &nbsp;&nbsp;&nbsp; 
<a href="README-Splits.md" id="links">Data splits</a>  &nbsp;&nbsp;&nbsp; | &nbsp;&nbsp;&nbsp; 
<a href="README-Downloads.md" id="links">Downloads</a>  &nbsp;&nbsp;&nbsp; | &nbsp;&nbsp;&nbsp; 
<a href="README-Loader.md" id="links">Data loader</a>  &nbsp;&nbsp;&nbsp; | &nbsp;&nbsp;&nbsp; 
<a href="README-Leaderboards.md" id="links">Leaderboards</a> </div>

------------------------------------------------------
<br>

Benchmark Challenges
================================================

The dataset has been used for multiple MICCAI EndoVis challenges.
During the challenges, a lot of deep learning methods were presented on the dataset and the challenge report published. Below are the official benchmark CholecTriplet challenges:

<br>

## <font color="gree"> CholecTriplet 2022</font>
For surgical action triplet detection.


This challenge extends our previous challenge on action triplet recognition to also include bounding box localization of the regions of action triplets. For the lack of spatially annotated dataset and to exploit large dataset without expensive and tedious annotation effort, this challenge focuses on the development and evaluation of weakly-supervised approaches for bounding box localization of action triplets on CholecT50 dataset.

- Visit challenge [website](https://cholectriplet2021.grand-challenge.org).

![image](../files/ct2022.png)

- Associated publication
> C.I. Nwoye, T. Yu, S. Sharma, A. Murali, D. Alapatt A. Vardazaryan, K. Yuan, ... , D. Mutter, N. Padoy. CholecTriplet2022: Show me a tool and tell me the triplet: an endoscopic vision challenge for surgical action triplet detection. arXiv PrePrint arXiv:2204.14746. 2023.
  ```  
  @article{nwoye2023cholectriplet2022,
    title={CholecTriplet2022: Show me a tool and tell me the triplet: an endoscopic vision challenge for surgical action triplet detection.},
    author={Nwoye, Chinedu Innocent and Yu, Tong and Sharma, Saurav and Murali, Aditya and Alapatt, Deepak and Vardazaryan, Armine ... Gonzalez, Cristians and Padoy, Nicolas},
    journal={arXiv preprint arXiv:2204.14746},
    year={2023}
  }
  ```
  <div align="right">
  
  [![Read on ArXiv](https://img.shields.io/badge/arxiv-2204.04746-red)](https://arxiv.org/abs/2204.04746)  
      
  </div>

-----

<br>

## <font color="gree"> CholecTriplet 2021</font>
For the recognition of surgical action triplet.

This challenge focuses on exploiting machine learning methods for the online automatic recognition of surgical actions as a series of triplets <instrument, verb, target>. Participants will develop and compete with algorithms to recognize action triplets directly from the provided surgical videos. This novel challenge investigates the state-of-the-art on surgical fine-grained activity recognition and will establish a new promising research direction in computer-assisted surgery.

- Visit challenge [website](https://cholectriplet2021.grand-challenge.org).

![image](../files/ct2021.png)

- Associated publication

> C.I. Nwoye, D. Alapatt, T. Yu, A. Vardazaryan, F. Xia, ... , C. Gonzalez, N. Padoy. CholecTriplet2021: a benchmark challenge for surgical action triplet recognition. arXiv PrePrint arXiv:2204.04746. Medical Image Analyssis 2022.

  ```
  @article{nwoye2022cholectriplet2021,
    title={CholecTriplet2021: a benchmark challenge for surgical action triplet recognition},
    author={Nwoye, Chinedu Innocent and Alapatt, Deepak and Vardazaryan, Armine ... Gonzalez, Cristians and Padoy, Nicolas},
    journal={arXiv preprint arXiv:2204.04746},
    year={2022}
  }
  ```
  
<div align="right">

  [![Read on ArXiv](https://img.shields.io/badge/arxiv-2204.04746-red)](https://arxiv.org/abs/2204.04746)  
      
 </div>

----------------------
